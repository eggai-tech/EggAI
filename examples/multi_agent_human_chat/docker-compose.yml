name: eggai-examples
networks:
  eggai-example-network:
    driver: bridge
volumes:
  redpanda: null
services:
  redpanda:
    command:
      - redpanda
      - start
      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
      - --advertise-kafka-addr internal://redpanda:9092,external://localhost:19092
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      - --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      - --rpc-addr redpanda:33145
      - --advertise-rpc-addr redpanda:33145
      - --mode dev-container
      - --smp 1
      - --default-log-level=info
    image: docker.redpanda.com/redpandadata/redpanda:v24.3.1
    container_name: redpanda
    volumes:
      - redpanda:/var/lib/redpanda/data
    networks:
      - eggai-example-network
    ports:
      - 18081:18081
      - 18082:18082
      - 19092:19092
      - 19644:9644
    healthcheck:
      test: ["CMD", "rpk", "cluster", "info", "--brokers=redpanda:9092"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s
  console:
    container_name: redpanda-console
    image: docker.redpanda.com/redpandadata/console:v2.8.0
    networks:
      - eggai-example-network
    entrypoint: /bin/sh
    command: -c 'echo "$$CONSOLE_CONFIG_FILE" > /tmp/config.yml; /app/console -config.filepath=${CONFIG_FILEPATH:-/tmp/config.yml}'
    environment:
      CONFIG_FILEPATH: ${CONFIG_FILEPATH:-/tmp/config.yml}
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["redpanda:9092"]
          schemaRegistry:
            enabled: true
            urls: ["http://redpanda:8081"]
        redpanda:
          adminApi:
            enabled: true
            urls: ["http://redpanda:9644"]
    ports:
      - 8080:8080
    depends_on:
      redpanda:
        condition: service_healthy
  topic-init:
    image: docker.redpanda.com/redpandadata/redpanda:v24.3.1
    container_name: topic-init
    networks:
      - eggai-example-network
    depends_on:
      redpanda:
        condition: service_healthy
    entrypoint: /bin/sh
    command: -c "
      echo 'Waiting for Redpanda cluster to be ready...' &&
      sleep 5 &&
      rpk topic create human --brokers=redpanda:9092 &&
      echo 'Topic humans created successfully!'" &&
      rpk topic create agents --brokers=redpanda:9092 &&
      echo 'Topic agents created successfully!'"
  otel-collector:
    image: otel/opentelemetry-collector:0.86.0
    command: [ "--config=/etc/otel-collector.yaml" ]
    volumes:
      - ./dockerConfig/otel-collector.yaml:/etc/otel-collector.yaml
    ports:
      - "4318:4318"
    networks:
      - eggai-example-network
  tempo:
    image: grafana/tempo:latest
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./dockerConfig/tempo.yaml:/etc/tempo.yaml
      - ./temp/tempo-data:/tmp/tempo
    ports:
      - "14268:14268"
      - "3200"
      - "4317:4317"
      - "9411:9411"
      - "16686"
    networks:
      - eggai-example-network
  prometheus:
    image: prom/prometheus:latest
    command:
      - --config.file=/etc/prometheus.yaml
      - --web.enable-remote-write-receiver
      - --enable-feature=exemplar-storage
      - --enable-feature=native-histograms
    volumes:
      - ./dockerConfig/prometheus.yaml:/etc/prometheus.yaml
    ports:
      - "9090:9090"
    networks:
      - eggai-example-network
  grafana:
    image: grafana/grafana:latest
    volumes:
      - ./dockerConfig/grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
      - ./dockerConfig/grafana-dashboard.json:/var/lib/grafana/dashboards/grafana-dashboard.json
      - ./dockerConfig/grafana-provisioning.yaml:/etc/grafana/provisioning/dashboards/dashboard.yaml
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
    ports:
      - "3000:3000"
    networks:
      - eggai-example-network
  minio-setup:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: [ "/bin/sh", "-c", "sleep 5 && mc alias set minio http://minio:9000 user password && mc mb -p minio/mlflow && mc anonymous set download minio/mlflow && echo 'MinIO bucket setup completed successfully'" ]
    networks:
      - eggai-example-network
  minio:
    image: minio/minio
    expose:
      - "9000"
    ports:
      - "9000:9000"
      # MinIO Console is available at http://localhost:9001
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: "user"
      MINIO_ROOT_PASSWORD: "password"
    command: server /data --console-address ":9001"
    healthcheck:
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9000' || exit 1
      interval: 1s
      timeout: 10s
      retries: 5
    networks:
      - eggai-example-network
  mlflow-artifacts-server:
    build:
      context: .
      dockerfile: "mlflow.Dockerfile"
    depends_on:
      - minio
      - minio-setup
    expose:
      - "5500"
    ports:
      - "5500:5500"
    environment:
      # MinIO credentials
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: "user"
      AWS_SECRET_ACCESS_KEY: "password"
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5500
      --artifacts-destination s3://mlflow
      --gunicorn-opts "--log-level debug"
      --artifacts-only
    networks:
      - eggai-example-network
  postgres:
    image: postgres
    environment:
      POSTGRES_DB: db
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    networks:
      - eggai-example-network
  mlflow-tracking-server:
    build:
      context: .
      dockerfile: "mlflow.Dockerfile"
    depends_on:
      - postgres
      - mlflow-artifacts-server
    expose:
      - "5001"
    ports:
      # MLflow UI is available at http://localhost:5001
      - "5001:5001"
    environment:
      # For external client connections
      MLFLOW_ARTIFACT_ROOT: http://localhost:5500/api/2.0/mlflow-artifacts/artifacts
      # Direct S3 access to MinIO
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: "user"
      AWS_SECRET_ACCESS_KEY: "password"
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5001
      --backend-store-uri postgresql://user:password@postgres:5432/db
      --default-artifact-root s3://mlflow
      --gunicorn-opts "--log-level debug"
    networks:
      - eggai-example-network
  lmstudio:
    runtime: nvidia
    image: vorobiev/gemma-3-4b-it:6
    command:
      - "--server"
      - "--nobrowser"
      - "-ngl"
      - "9999"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "1234"
      - "--gpu-layers"
      - "30"
    ports:
      - "1234:1234"
    networks:
      - eggai-example-network
